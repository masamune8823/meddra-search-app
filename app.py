
import streamlit as st
import pandas as pd
import numpy as np
import faiss
import openai
import os
import pickle
import re

from helper_functions import (
    search_meddra,
    rerank_results_v13,
    predict_soc_keywords_with_gpt,
    add_hierarchy_info
)

# term_master_df èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°ï¼‰
term_master_df = None
try:
    with open("term_master_df.pkl", "rb") as f:
        term_master_df = pickle.load(f)
except Exception as e:
    st.warning(f"term_master_df ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {e}")

def clean_keywords(raw_keywords):
    cleaned = []
    for kw in raw_keywords:
        # è¡Œé ­ã®ç•ªå·ã‚„è¨˜å·é™¤å» â†’ ä¾‹ï¼š"1. ã‹ã‚†ã¿" â†’ "ã‹ã‚†ã¿"
        kw = re.sub(r"^[0-9ï¼-ï¼™]+[\.ï¼ã€:\s]*", "", kw)
        kw = kw.strip("ãƒ» 0123456789.ã€‚ã€:ï¼š\n")
        if len(kw) > 1:
            cleaned.append(kw)
    return cleaned

def main():
    st.title("ğŸ” MedDRAæ¤œç´¢ã‚¢ãƒ—ãƒª")
    query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    if query:
        st.markdown("## ğŸ” å…¥åŠ›ã‚¯ã‚¨ãƒª")
        st.write(query)

        # GPTã§SOCã‚«ãƒ†ã‚´ãƒªã‚’äºˆæ¸¬ï¼ˆã‚¯ã‚¨ãƒªæ‹¡å¼µï¼‰
        with st.spinner("GPTã§æ‹¡å¼µèªã‚’ç”Ÿæˆä¸­..."):
            raw_keywords = predict_soc_keywords_with_gpt(query)
            cleaned_keywords = clean_keywords(raw_keywords)
            st.markdown("#### ğŸ§  GPTäºˆæ¸¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ•´å½¢å¾Œï¼‰")
            st.write(cleaned_keywords)

        # é¡ä¼¼èªæ¤œç´¢ï¼ˆFAISSï¼‰
        with st.spinner("FAISSã§ç”¨èªæ¤œç´¢ä¸­..."):
            search_results = []
            for kw in cleaned_keywords:
                result = search_meddra(kw)
                search_results.append(result)
            all_results = pd.concat(search_results).drop_duplicates(subset=["term"]).reset_index(drop=True)

        # å†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        with st.spinner("å†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¸­..."):
            reranked = rerank_results_v13(all_results, query)

        # éšå±¤æƒ…å ±è¿½åŠ 
        if term_master_df is not None:
            reranked = add_hierarchy_info(reranked, term_master_df)

        # åˆ—åå¤‰æ›
        reranked = reranked.rename(columns={
            "term": "ç”¨èª",
            "score": "ç¢ºã‹ã‚‰ã—ã•ï¼ˆï¼…ï¼‰",
            "HLT_Japanese": "HLT",
            "HLGT_Japanese": "HLGT",
            "SOC_Japanese": "SOC"
        })

        # ä¸¦ã¹æ›¿ãˆ
        if "ç¢ºã‹ã‚‰ã—ã•ï¼ˆï¼…ï¼‰" in reranked.columns:
            sorted_df = reranked.sort_values(by="ç¢ºã‹ã‚‰ã—ã•ï¼ˆï¼…ï¼‰", ascending=False).reset_index(drop=True)
        else:
            sorted_df = reranked

        # è¡¨ç¤º
        display_columns = [col for col in ["ç”¨èª", "ç¢ºã‹ã‚‰ã—ã•ï¼ˆï¼…ï¼‰", "HLT", "HLGT", "SOC"] if col in sorted_df.columns]
        st.markdown("## ğŸ“ æ¤œç´¢çµæœï¼ˆã‚¹ã‚³ã‚¢é †ï¼‰")
        st.dataframe(sorted_df[display_columns])

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv = sorted_df.to_csv(index=False).encode("utf-8")
        st.download_button("ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="meddra_results.csv", mime="text/csv")

if __name__ == "__main__":
    main()
