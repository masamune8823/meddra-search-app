import numpy as np
import pandas as pd
import faiss
import openai
import pickle
from sentence_transformers import SentenceTransformer

# ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆMiniLMï¼‰
encoder = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

def encode_query(query: str):
    return encoder.encode(query)

# ðŸ” MedDRAæ¤œç´¢ï¼ˆsynonym_df + FAISSï¼‰
def search_meddra(query, faiss_index, meddra_terms, synonym_df=None, top_k=20):
    results = []

    # ãƒ¡ã‚¤ãƒ³ã‚¯ã‚¨ãƒªã§æ¤œç´¢
    query_vec = encode_query(query)
    D, I = faiss_index.search(np.array([query_vec]), top_k)
    for i, score in zip(I[0], D[0]):
        results.append({
            "term": meddra_terms[i],
            "score": float(score),
            "source": "main"
        })

    # ã‚·ãƒŽãƒ‹ãƒ ãŒã‚ã‚Œã°è¿½åŠ æ¤œç´¢
    if synonym_df is not None and query in synonym_df.index:
        synonyms = synonym_df.loc[query]["synonyms"]
        for syn in synonyms:
            syn_vec = encode_query(syn)
            D_syn, I_syn = faiss_index.search(np.array([syn_vec]), top_k)
            for i, score in zip(I_syn[0], D_syn[0]):
                results.append({
                    "term": meddra_terms[i],
                    "score": float(score),
                    "source": f"syn:{syn}"
                })

    return pd.DataFrame(results).drop_duplicates(subset="term").reset_index(drop=True)

# ðŸŽ¯ GPTå†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
def rerank_results_v13(query, df, top_n=10):
    if df.empty:
        return df

    terms = df["term"].tolist()[:top_n]
    prompt = (
        f"ä»¥ä¸‹ã®ç—‡çŠ¶ã«ã©ã‚Œã ã‘é–¢é€£ãŒã‚ã‚‹ã‹ã‚’100ç‚¹æº€ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š{query}\n"
        "å„ç”¨èªžã”ã¨ã«ã€Œã‚¹ã‚³ã‚¢ã®ã¿ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )

    messages = [{"role": "user", "content": prompt + "\n" + "\n".join(terms)}]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0,
        )
        reply = response["choices"][0]["message"]["content"]
        lines = reply.strip().split("\n")
        scores = {}
        for line in lines:
            for term in terms:
                if term in line:
                    num = "".join([c for c in line if c.isdigit()])
                    scores[term] = int(num) if num else 0

        df["score"] = df["term"].map(scores).fillna(0)
        df["score"] = df["score"].astype(int)
        return df.sort_values("score", ascending=False).reset_index(drop=True)

    except Exception as e:
        print(f"Error in reranking: {e}")
        df["score"] = 0
        return df

# ðŸŽ¯ GPTã«ã‚ˆã‚‹SOCã‚«ãƒ†ã‚´ãƒªäºˆæ¸¬
def predict_soc_keywords_with_gpt(query):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯åŒ»ç™‚åˆ†é‡Žã«è©³ã—ã„AIã§ã™ã€‚ä¸Žãˆã‚‰ã‚ŒãŸç—‡çŠ¶ã«é–¢é€£ã™ã‚‹MedDRAã®SOCã‚«ãƒ†ã‚´ãƒªã‚’3ã¤ã€æ—¥æœ¬èªžã§ç°¡æ½”ã«äºˆæ¸¬ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": f"ä»¥ä¸‹ã®ç—‡çŠ¶ã«é–¢é€£ã™ã‚‹SOCã‚«ãƒ†ã‚´ãƒªã‚’æ•™ãˆã¦ãã ã•ã„ï¼š\n\n{query}"}
        ],
        temperature=0.3,
    )
    text = response["choices"][0]["message"]["content"]
    keywords = [kw.strip("ãƒ» ã€ã€‚\n") for kw in text.split() if kw.strip()]
    return keywords[:3]

# ðŸŽ¯ SOCã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
def filter_by_predicted_soc(df, keywords):
    if not keywords:
        return df
    cols = ["SOC", "HLGT", "HLT"]
    cols = [col for col in cols if col in df.columns]
    if not cols:
        return df
    mask = df[cols].apply(lambda x: x.astype(str).str.contains("|".join(keywords)).any(), axis=1)
    return df[mask].copy()

# ðŸ”§ ã‚¹ã‚³ã‚¢ã®å†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆæœ€å¤§å€¤100ã«ï¼‰
def rescale_scores(df, col="score"):
    if col in df.columns and df[col].max() > 0:
        df[col] = (df[col] / df[col].max()) * 100
        df[col] = df[col].round(1)
    return df
