import streamlit as st
import numpy as np
import pickle
import faiss
import os

from helper_functions import expand_query_gpt, encode_query, rerank_results_v13

@st.cache_resource
def load_faiss_index():
    index = faiss.read_index("faiss_index.index")
    return index

@st.cache_resource
def load_embeddings():
    return np.load("meddra_embeddings.npy")

@st.cache_resource
def load_term_master():
    with open("term_master_df.pkl", "rb") as f:
        return pickle.load(f)

@st.cache_resource
def load_synonym_dict():
    with open("synonym_df_cat1.pkl", "rb") as f:
        return pickle.load(f)

@st.cache_resource
def load_search_assets():
    assets = []
    for part in ['a', 'b', 'c', 'd']:
        filename = f"search_assets_part_{part}"
        with open(filename, "rb") as f:
            assets.append(pickle.load(f))
    return assets

# ã‚¢ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
index = load_faiss_index()
embeddings = load_embeddings()
term_master_df = load_term_master()
synonym_df_cat1 = load_synonym_dict()
search_assets = load_search_assets()

# Streamlit UI
st.set_page_config(page_title="MedDRAæ¤œç´¢ã‚¢ãƒ—ãƒª", layout="centered")
st.title("ğŸ’Š MedDRAæ¤œç´¢ã‚¢ãƒ—ãƒª")
st.write("ç—‡çŠ¶ã‚„è¨˜è¿°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

query = st.text_input("ç—‡çŠ¶å…¥åŠ›", value="")

if st.button("æ¤œç´¢"):
    if not query.strip():
        st.warning("æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        try:
            # æ‹¡å¼µ
            expanded_terms = expand_query_gpt(query, synonym_df_cat1)
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_vector = encode_query(expanded_terms)
            # FAISSæ¤œç´¢
            D, I = index.search(query_vector, k=10)
            # å€™è£œå–å¾—
            candidates = [search_assets[i] for i in I[0]]
            # å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            reranked_df = rerank_results_v13(query, candidates, term_master_df)
            # è¡¨ç¤º
            st.dataframe(reranked_df)

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
