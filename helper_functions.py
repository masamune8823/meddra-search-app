# âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã«ä¸€åº¦ã ã‘æ›¸ã
from openai import OpenAI
client = OpenAI()

import os
import re
import pickle
import openai
import faiss
import numpy as np
import pandas as pd
import torch
from sentence_transformers import SentenceTransformer

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# OpenAI APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
openai.api_key = os.getenv("OPENAI_API_KEY")

# ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
def encode_query(text):
    return model.encode([text])[0]

# æ¤œç´¢å‡¦ç†æœ¬ä½“
def search_meddra(query, faiss_index, meddra_terms, synonym_df=None, top_k=10):
    query_vector = encode_query(query).astype(np.float32)
    distances, indices = faiss_index.search(np.array([query_vector]), top_k)
    results = []
    for i in range(len(indices[0])):
        idx = indices[0][i]
        if idx < len(meddra_terms):
            term = meddra_terms[idx]
            score = float(distances[0][i])
            results.append({"term": term, "score": score})
    return pd.DataFrame(results)

#  ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼ã«ã‚ˆã‚‹PTå€™è£œæç¤º
def suggest_similar_terms(query, faiss_index, meddra_terms, top_k=10):
    """
    ã‚¯ã‚¨ãƒªã«æ„å‘³çš„ã«è¿‘ã„PTå€™è£œã‚’ã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã‚ˆã‚Šå–å¾—ã™ã‚‹ã€‚
    """
    query_vector = encode_query(query).astype(np.float32)
    distances, indices = faiss_index.search(np.array([query_vector]), top_k)
    suggestions = [meddra_terms[idx] for idx in indices[0] if idx < len(meddra_terms)]
    return suggestions
   
# å›ç­”ã‹ã‚‰ã‚¹ã‚³ã‚¢æŠ½å‡ºï¼ˆå˜ç´”å®Ÿè£…ï¼‰
def extract_score_from_response(response_text):
    for word in ["10", "ï¼™", "8", "ï¼—", "6", "5", "4", "3", "2", "1", "0"]:
        if word in response_text:
            try:
                return float(word)
            except:
                continue
    return 5.0  # fallback

# ã‚¹ã‚³ã‚¢ã®å†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
def rescale_scores(scores):
    min_score = min(scores)
    max_score = max(scores)
    if max_score == min_score:
        return [100.0 for _ in scores]
    return [100.0 * (s - min_score) / (max_score - min_score) for s in scores]

# âœ… å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‡¦ç†ï¼ˆGPTä¸€æ‹¬å‘¼ã³å‡ºã—ç‰ˆï¼‰
# âœ… GPTå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‡¦ç†ï¼ˆ1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ï¼‰
def rerank_results_batch(query, candidates, score_cache=None):
    if score_cache is None:
        score_cache = {}

    top_candidates = candidates.head(10)

    # æœªã‚¹ã‚³ã‚¢ã® term ã ã‘ã‚’æŠ½å‡º
    new_terms = []
    for i, row in top_candidates.iterrows():
        term = row["term"]
        if (query, term) not in score_cache:
            new_terms.append(term)
    # âœ… ã‚¹ã‚³ã‚¢å¯¾è±¡ã®èªæ•°ã¨ä¸­èº«ã‚’Streamlitã§è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    import streamlit as st
    st.write("ğŸ§ª ã‚¹ã‚³ã‚¢æœªè©•ä¾¡èªæ•°:", len(new_terms), "ä»¶")
    st.write("ğŸ§ª æœªè©•ä¾¡èªãƒªã‚¹ãƒˆ:", new_terms)
    
    if new_terms:
        # ğŸ”§ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦ï¼ˆ1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å…¨termï¼‰
        prompt = f"""ä»¥ä¸‹ã®è¨˜è¿°ã€Œ{query}ã€ã«å¯¾ã—ã¦ã€å„ç”¨èªãŒã©ã‚Œãã‚‰ã„æ„å‘³çš„ã«ä¸€è‡´ã™ã‚‹ã‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
ä¸€è‡´åº¦ã‚’ 0ã€œ10 ã®æ•°å€¤ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

"""
        for idx, term in enumerate(new_terms, 1):
            prompt += f"{idx}. {term}\n"

        prompt += "\nå½¢å¼ï¼š\n1. 7\n2. 5\n... ã®ã‚ˆã†ã«è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚"

        messages = [
            {"role": "system", "content": "ã‚ãªãŸã¯åŒ»ç™‚ç”¨èªã®é–¢é€£æ€§ã‚’æ•°å€¤ã§åˆ¤æ–­ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
            {"role": "user", "content": prompt}
        ]

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0,
            )
            content = response.choices[0].message.content

            # âœ… Streamlitãƒ­ã‚°è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            import streamlit as st
            st.subheader("ğŸ§¾ GPTãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ï¼ˆä¸€æ‹¬å½¢å¼ï¼‰")
            st.code(content)

            # æ•°å€¤æŠ½å‡ºï¼ˆå½¢å¼ï¼š1. 7ï¼‰
            for line in content.strip().split("\n"):
                if "." in line:
                    parts = line.split(".")
                    try:
                        idx = int(parts[0].strip())
                        score = extract_score_from_response(line)
                        term = new_terms[idx - 1]
                        score_cache[(query, term)] = score
                    except:
                        continue
        except Exception as e:
            for term in new_terms:
                score_cache[(query, term)] = 5.0  # fallback

    # ã‚¹ã‚³ã‚¢ã‚’ã¾ã¨ã‚ã¦è¿”ã™
    scored = [(term, score_cache.get((query, term), 5.0)) for term in top_candidates["term"]]
    df = pd.DataFrame(scored, columns=["term", "Relevance"])
    return df.sort_values(by="Relevance", ascending=False)


# GPTã§SOCã‚«ãƒ†ã‚´ãƒªã‚’äºˆæ¸¬
def predict_soc_category(query):
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯MedDRAã®SOCã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®šã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
        {"role": "user", "content": f"æ¬¡ã®ç—‡çŠ¶ã«æœ€ã‚‚é–¢é€£ã™ã‚‹MedDRAã®SOCã‚«ãƒ†ã‚´ãƒªã‚’1ã¤ã ã‘ã€æ—¥æœ¬èªã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œç¥çµŒç³»éšœå®³ã€ãªã©ï¼‰ã€‚\n\nç—‡çŠ¶: {query}"}
    ]
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return "ä¸æ˜"

# ã‚¯ã‚¨ãƒªæ‹¡å¼µï¼ˆGPTä½¿ç”¨ï¼‰
def expand_query_gpt(query):
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯æ—¥æœ¬èªåŒ»ç™‚æ–‡ã‚’è‹±èªã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¤‰æ›ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
        {"role": "user", "content": f"ä»¥ä¸‹ã®æ—¥æœ¬èªã®ç—‡çŠ¶ã‹ã‚‰ã€è‹±èªã®åŒ»å­¦çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’3ã¤äºˆæ¸¬ã—ã¦ãã ã•ã„ã€‚\n\nç—‡çŠ¶: {query}"}
    ]
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0,
        )
        response_text = response.choices[0].message.content
        return [kw.strip() for kw in response_text.split(",") if kw.strip()]
    except Exception as e:
        return ["headache", "nausea", "fever"]

# è¡¨ç¤ºæ•´å½¢ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆï¼‰
def format_keywords(keywords):
    return "ã€".join(keywords)

# MedDRAéšå±¤æƒ…å ±ã‚’ä»˜ä¸
def add_hierarchy_info(df, term_master_df):
    merged = pd.merge(df, term_master_df, how="left", left_on="term", right_on="PT_English")
    return merged
    
# âœ… æ—¥æœ¬èªPTï¼ˆPT_Japaneseï¼‰ã§éšå±¤æƒ…å ±ã‚’ãƒãƒ¼ã‚¸ã™ã‚‹é–¢æ•°
def add_hierarchy_info_jp(df, term_master_df):
    return pd.merge(df, term_master_df, how="left", left_on="term", right_on="PT_Japanese")
