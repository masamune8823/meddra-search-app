
import streamlit as st
import pickle
import os
import numpy as np
import pandas as pd

from helper_functions import (
    encode_query,
    search_meddra,
    rerank_results_v13,
    expand_query_gpt,
    predict_soc_category,
    format_keywords,
    rescale_scores,
    add_hierarchy_info,
    load_score_cache,
    save_score_cache
)

@st.cache_resource
def load_faiss_index(path):
    import faiss
    return faiss.read_index(path)

@st.cache_data
def load_assets():
    index = load_faiss_index("faiss_index.index")
    terms = np.load("meddra_terms.npy", allow_pickle=True)
    synonym_df = pd.read_pickle("synonym_df_cat1.pkl")
    term_master_df = pd.read_pickle("term_master_df.pkl")
    return index, terms, synonym_df, term_master_df

# ã‚¢ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ‰
faiss_index, meddra_terms, synonym_df, term_master_df = load_assets()
score_cache = load_score_cache()

st.title("ğŸ’Š MedDRA ç”¨èªæ¤œç´¢ã‚¢ãƒ—ãƒª")
query = st.text_input("ç—‡çŠ¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆæ—¥æœ¬èªï¼‰", "")

if st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ") and query:
    st.write("ğŸ”„ OpenAIã‚’ä½¿ã£ã¦æ¤œç´¢èªã‚’æ‹¡å¼µä¸­...")
    predicted_keywords = expand_query_gpt(query)
    st.write("ğŸ”‘ æ‹¡å¼µã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:", format_keywords(predicted_keywords))

    with st.spinner("FAISSã§ç”¨èªæ¤œç´¢ä¸­..."):
        search_results = []
        for kw in predicted_keywords:
            result = search_meddra(kw, faiss_index, meddra_terms, synonym_df, top_k=20)
            search_results.append(result)
        all_results = pd.concat(search_results).drop_duplicates(subset=["term"]).reset_index(drop=True)

    with st.spinner("OpenAIã§å†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¸­..."):
        all_results = rerank_results_v13(query, all_results, score_cache)

    with st.spinner("MedDRAéšå±¤æƒ…å ±ã‚’è¿½åŠ ä¸­..."):
        all_results = add_hierarchy_info(all_results, term_master_df)

    st.success("æ¤œç´¢å®Œäº†ï¼")
    st.dataframe(all_results)

    save_score_cache(score_cache)
