import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os

from helper_functions import (
    encode_query,
    search_meddra,
    rerank_results_v13,
    add_hierarchy_info,
    rescale_scores,
    predict_soc_category,
    format_keywords,
)

# ---------------- åˆæœŸè¨­å®š ---------------- #
st.set_page_config(page_title="MedDRAæ¤œç´¢ã‚¢ãƒ—ãƒª", page_icon="ğŸ”")
st.title("\U0001f50d MedDRAæ¤œç´¢ã‚¢ãƒ—ãƒª")

# ---------------- ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ---------------- #
@st.cache_resource
def load_assets():
    with open("search_assets_part_a", "rb") as f:
        faiss_index = pickle.load(f)
    with open("search_assets_part_b", "rb") as f:
        meddra_terms = pickle.load(f)
    with open("search_assets_part_c", "rb") as f:
        synonym_df = pickle.load(f)
    with open("search_assets_part_d", "rb") as f:
        term_master_df = pickle.load(f)
    return faiss_index, meddra_terms, synonym_df, term_master_df

faiss_index, meddra_terms, synonym_df, term_master_df = load_assets()

# ---------------- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ› ---------------- #
query = st.text_input("æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šçš®è†šãŒã‹ã‚†ã„ï¼‰", value="ã‚ºã‚­ã‚ºã‚­")
use_soc_filter = st.checkbox("GPTã«ã‚ˆã‚‹SOCäºˆæ¸¬ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ¨å¥¨ï¼‰", value=True)

# ---------------- æ¤œç´¢å‡¦ç† ---------------- #
if st.button("æ¤œç´¢"):
    if not query.strip():
        st.warning("æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è§£æä¸­..."):
            predicted_keywords = predict_soc_category(query)
            st.subheader("\ud83e\udd13 GPTäºˆæ¸¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ•´å½¢å¾Œï¼‰")
            st.write(predicted_keywords)

        with st.spinner("FAISSã§ç”¨èªæ¤œç´¢ä¸­..."):
            search_results = []
            for kw in predicted_keywords:
                result = search_meddra(kw, faiss_index, meddra_terms, synonym_df, top_k=20)
                search_results.append(result)
            all_results = pd.concat(search_results).drop_duplicates(subset=["term"]).reset_index(drop=True)

        with st.spinner("å†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¸­ï¼ˆGPTï¼‰..."):
            reranked = rerank_results_v13(query, all_results)
            reranked = rescale_scores(reranked)

        with st.spinner("éšå±¤æƒ…å ±ã‚’ä»˜åŠ ä¸­..."):
            final_results = add_hierarchy_info(reranked, term_master_df)

        if use_soc_filter:
            try:
                soc_prediction = predict_soc_category(query)
                final_results = final_results[final_results["SOC"].isin(soc_prediction)]
            except Exception as e:
                st.warning(f"ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        st.success("æ¤œç´¢å®Œäº†")
        st.dataframe(final_results[["term", "score", "HLT", "HLGT", "SOC"]].rename(columns={"term": "ç”¨èª", "score": "ç¢ºã‹ã‚‰ã—ã• (%)"}))

        csv = final_results.to_csv(index=False).encode("utf-8")
        st.download_button("\ud83d\udcc6 çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="meddra_results.csv", mime="text/csv")
        
        # ğŸ” ãƒ†ã‚¹ãƒˆç”¨ãƒœã‚¿ãƒ³ï¼ˆâ† ã“ã“ãŒè¿½è¨˜éƒ¨åˆ†ï¼‰
        if st.button("ğŸ” ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆã‚ºã‚­ã‚ºã‚­ï¼‰"):
            from test_meddra_full_pipeline import run_test_pipeline
            run_test_pipeline()
        # updated

